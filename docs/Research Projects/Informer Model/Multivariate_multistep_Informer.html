<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.353">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Deepak Bastola - Informer</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../img/favicon.png" rel="icon" type="image/png">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>


<link rel="stylesheet" href="../../html/styles.scss">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a href="../../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../img/logo.png" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Deepak Bastola</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../Research Projects/index.html" rel="" target="">
 <span class="menu-text">Research Projects</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../Courses/index.html" rel="" target="">
 <span class="menu-text">Courses</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../CV/index.html" rel="" target="">
 <span class="menu-text">CV</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://deepbas.io/" rel="" target=""><i class="bi bi-folder-symlink" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/aphsansar" rel="" target=""><i class="bi bi-twitter" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/deepakbastola/" rel="" target=""><i class="bi bi-linkedin" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="mailto:deepbas@gmail.com" rel="" target=""><i class="bi bi-envelope" role="img" aria-label="email">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#probsparse-self-attention" id="toc-probsparse-self-attention" class="nav-link active" data-scroll-target="#probsparse-self-attention">ProbSparse Self-Attention:</a></li>
  <li><a href="#informer-encoder" id="toc-informer-encoder" class="nav-link" data-scroll-target="#informer-encoder">Informer Encoder:</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content column-page-left" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Informer</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<div class="cell" data-outputid="88ba7467-0b13-4809-b07b-5b82aabbe860" data-execution_count="5">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install yfinance</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Requirement already satisfied: yfinance in /home/deepak/anaconda3/lib/python3.7/site-packages (0.1.81)
Requirement already satisfied: pandas&gt;=0.24.0 in /home/deepak/anaconda3/lib/python3.7/site-packages (from yfinance) (1.3.5)
Requirement already satisfied: numpy&gt;=1.15 in /home/deepak/anaconda3/lib/python3.7/site-packages (from yfinance) (1.21.5)
Requirement already satisfied: requests&gt;=2.26 in /home/deepak/anaconda3/lib/python3.7/site-packages (from yfinance) (2.31.0)
Requirement already satisfied: multitasking&gt;=0.0.7 in /home/deepak/anaconda3/lib/python3.7/site-packages (from yfinance) (0.0.11)
Requirement already satisfied: lxml&gt;=4.5.1 in /home/deepak/anaconda3/lib/python3.7/site-packages (from yfinance) (4.9.1)
Requirement already satisfied: appdirs&gt;=1.4.4 in /home/deepak/anaconda3/lib/python3.7/site-packages (from yfinance) (1.4.4)
Requirement already satisfied: python-dateutil&gt;=2.7.3 in /home/deepak/anaconda3/lib/python3.7/site-packages (from pandas&gt;=0.24.0-&gt;yfinance) (2.8.2)
Requirement already satisfied: pytz&gt;=2017.3 in /home/deepak/anaconda3/lib/python3.7/site-packages (from pandas&gt;=0.24.0-&gt;yfinance) (2023.3)
Requirement already satisfied: charset-normalizer&lt;4,&gt;=2 in /home/deepak/anaconda3/lib/python3.7/site-packages (from requests&gt;=2.26-&gt;yfinance) (2.1.1)
Requirement already satisfied: idna&lt;4,&gt;=2.5 in /home/deepak/anaconda3/lib/python3.7/site-packages (from requests&gt;=2.26-&gt;yfinance) (3.4)
Requirement already satisfied: urllib3&lt;3,&gt;=1.21.1 in /home/deepak/anaconda3/lib/python3.7/site-packages (from requests&gt;=2.26-&gt;yfinance) (2.0.4)
Requirement already satisfied: certifi&gt;=2017.4.17 in /home/deepak/anaconda3/lib/python3.7/site-packages (from requests&gt;=2.26-&gt;yfinance) (2023.7.22)
Requirement already satisfied: six&gt;=1.5 in /home/deepak/anaconda3/lib/python3.7/site-packages (from python-dateutil&gt;=2.7.3-&gt;pandas&gt;=0.24.0-&gt;yfinance) (1.16.0)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> MinMaxScaler</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> mean_squared_error</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> yfinance <span class="im">as</span> yf</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-outputid="50f0a018-d638-41e4-f423-dbaba6190b85" data-execution_count="8">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Download historical data as dataframe</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> yf.download(<span class="st">"AAPL"</span>, start<span class="op">=</span><span class="st">"2018-01-01"</span>, end<span class="op">=</span><span class="st">"2023-09-01"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[*********************100%***********************]  1 of 1 completed

1 Failed download:
- AAPL: No data found for this date range, symbol may be delisted</code></pre>
</div>
</div>
<p>The Informer model variant is designed for multivariate prediction. Let’s consider ‘Open’, ‘High’, ‘Low’, and ‘Close’ prices for simplicity. The provided code is designed to fetch and preprocess historical stock prices for Apple Inc.&nbsp;for the purpose of multivariate time series forecasting using an LSTM model. Initially, the code downloads Apple’s stock data, specifically capturing four significant features: Open, High, Low, and Close prices. To make the data suitable for deep learning models, it is normalized to fit within a range of 0 to 1. The sequential data is then transformed into a format suitable for supervised learning, where the data from the past <code>look_back</code> days is used to predict the next day’s features. Finally, the data is partitioned into training (67%) and test sets, ensuring separate datasets for model training and evaluation.</p>
<div class="cell" data-outputid="ae365cc3-d7e3-4584-ca16-15cc98e1304c" data-execution_count="3">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Using multiple columns for multivariate prediction</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> data[[<span class="st">"Open"</span>, <span class="st">"High"</span>, <span class="st">"Low"</span>, <span class="st">"Close"</span>]]</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Normalize the data</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> MinMaxScaler(feature_range<span class="op">=</span>(<span class="dv">0</span>, <span class="dv">1</span>))</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>df_scaled <span class="op">=</span> scaler.fit_transform(df)</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Prepare data for LSTM</span></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>look_back <span class="op">=</span> <span class="dv">10</span>  <span class="co"># Number of previous time steps to use as input variables</span></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>n_features <span class="op">=</span> df.shape[<span class="dv">1</span>]  <span class="co"># number of features</span></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert to supervised learning problem</span></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>X, y <span class="op">=</span> [], []</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(df_scaled) <span class="op">-</span> look_back):</span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>    X.append(df_scaled[i:i<span class="op">+</span>look_back, :])</span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>    y.append(df_scaled[i <span class="op">+</span> look_back, :])</span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>X, y <span class="op">=</span> np.array(X), np.array(y)</span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Reshape input to be [samples, time steps, features]</span></span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.reshape(X, (X.shape[<span class="dv">0</span>], X.shape[<span class="dv">1</span>], n_features))</span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Train-test split</span></span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a>train_size <span class="op">=</span> <span class="bu">int</span>(<span class="bu">len</span>(X) <span class="op">*</span> <span class="fl">0.67</span>)</span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a>test_size <span class="op">=</span> <span class="bu">len</span>(X) <span class="op">-</span> train_size</span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a>X_train, X_test <span class="op">=</span> X[<span class="dv">0</span>:train_size], X[train_size:]</span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a>y_train, y_test <span class="op">=</span> y[<span class="dv">0</span>:train_size], y[train_size:]</span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-28"><a href="#cb6-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(X_train.shape, y_train.shape, X_test.shape, y_test.shape)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-error">
<pre><code>NameError: name 'data' is not defined</code></pre>
</div>
</div>
<section id="probsparse-self-attention" class="level1">
<h1>ProbSparse Self-Attention:</h1>
<p>Self-attention involves computing a weighted sum of all values in the sequence, based on the dot product between the query and key. In ProbSparse, we don’t compute this for all query-key pairs, but rather select dominant ones, thus making the computation more efficient. The given code defines a custom Keras layer, <code>ProbSparseSelfAttention</code>, which implements the multi-head self-attention mechanism, a critical component of Transformer models. This layer initializes three dense networks for the Query, Key, and Value matrices, and splits the input data into multiple heads to enable parallel processing. During the forward pass (<code>call</code> method), the Query, Key, and Value matrices are calculated, scaled, and then used to compute attention scores. These scores indicate the importance of each element in the sequence when predicting another element. The output is a weighted sum of the input values, which is then passed through another dense layer to produce the final result.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> ProbSparseSelfAttention(tf.keras.layers.Layer):</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, d_model, num_heads, <span class="op">**</span>kwargs):</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(ProbSparseSelfAttention, <span class="va">self</span>).<span class="fu">__init__</span>(<span class="op">**</span>kwargs)</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.num_heads <span class="op">=</span> num_heads</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.d_model <span class="op">=</span> d_model</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Assert that d_model is divisible by num_heads</span></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>        <span class="cf">assert</span> <span class="va">self</span>.d_model <span class="op">%</span> <span class="va">self</span>.num_heads <span class="op">==</span> <span class="dv">0</span>, <span class="ss">f"d_model (</span><span class="sc">{</span>d_model<span class="sc">}</span><span class="ss">) must be divisible by num_heads (</span><span class="sc">{</span>num_heads<span class="sc">}</span><span class="ss">)"</span></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.depth <span class="op">=</span> d_model <span class="op">//</span> <span class="va">self</span>.num_heads</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Defining the dense layers for Query, Key and Value</span></span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.wq <span class="op">=</span> tf.keras.layers.Dense(d_model)</span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.wk <span class="op">=</span> tf.keras.layers.Dense(d_model)</span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.wv <span class="op">=</span> tf.keras.layers.Dense(d_model)</span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dense <span class="op">=</span> tf.keras.layers.Dense(d_model)</span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> split_heads(<span class="va">self</span>, x, batch_size):</span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> tf.reshape(x, (batch_size, <span class="op">-</span><span class="dv">1</span>, <span class="va">self</span>.num_heads, <span class="va">self</span>.depth))</span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> tf.transpose(x, perm<span class="op">=</span>[<span class="dv">0</span>, <span class="dv">2</span>, <span class="dv">1</span>, <span class="dv">3</span>])</span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> call(<span class="va">self</span>, v, k, q):</span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true" tabindex="-1"></a>        batch_size <span class="op">=</span> tf.shape(q)[<span class="dv">0</span>]</span>
<span id="cb8-25"><a href="#cb8-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-26"><a href="#cb8-26" aria-hidden="true" tabindex="-1"></a>        q <span class="op">=</span> <span class="va">self</span>.wq(q)</span>
<span id="cb8-27"><a href="#cb8-27" aria-hidden="true" tabindex="-1"></a>        k <span class="op">=</span> <span class="va">self</span>.wk(k)</span>
<span id="cb8-28"><a href="#cb8-28" aria-hidden="true" tabindex="-1"></a>        v <span class="op">=</span> <span class="va">self</span>.wv(v)</span>
<span id="cb8-29"><a href="#cb8-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-30"><a href="#cb8-30" aria-hidden="true" tabindex="-1"></a>        q <span class="op">=</span> <span class="va">self</span>.split_heads(q, batch_size)</span>
<span id="cb8-31"><a href="#cb8-31" aria-hidden="true" tabindex="-1"></a>        k <span class="op">=</span> <span class="va">self</span>.split_heads(k, batch_size)</span>
<span id="cb8-32"><a href="#cb8-32" aria-hidden="true" tabindex="-1"></a>        v <span class="op">=</span> <span class="va">self</span>.split_heads(v, batch_size)</span>
<span id="cb8-33"><a href="#cb8-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-34"><a href="#cb8-34" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Fixing matrix multiplication</span></span>
<span id="cb8-35"><a href="#cb8-35" aria-hidden="true" tabindex="-1"></a>        matmul_qk <span class="op">=</span> tf.matmul(q, k, transpose_b<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb8-36"><a href="#cb8-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-37"><a href="#cb8-37" aria-hidden="true" tabindex="-1"></a>        d_k <span class="op">=</span> tf.cast(<span class="va">self</span>.depth, tf.float32)</span>
<span id="cb8-38"><a href="#cb8-38" aria-hidden="true" tabindex="-1"></a>        scaled_attention_logits <span class="op">=</span> matmul_qk <span class="op">/</span> tf.math.sqrt(d_k)</span>
<span id="cb8-39"><a href="#cb8-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-40"><a href="#cb8-40" aria-hidden="true" tabindex="-1"></a>        attention_weights <span class="op">=</span> tf.nn.softmax(scaled_attention_logits, axis<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb8-41"><a href="#cb8-41" aria-hidden="true" tabindex="-1"></a>        output <span class="op">=</span> tf.matmul(attention_weights, v)</span>
<span id="cb8-42"><a href="#cb8-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-43"><a href="#cb8-43" aria-hidden="true" tabindex="-1"></a>        output <span class="op">=</span> tf.transpose(output, perm<span class="op">=</span>[<span class="dv">0</span>, <span class="dv">2</span>, <span class="dv">1</span>, <span class="dv">3</span>])</span>
<span id="cb8-44"><a href="#cb8-44" aria-hidden="true" tabindex="-1"></a>        concat_attention <span class="op">=</span> tf.reshape(output, (batch_size, <span class="op">-</span><span class="dv">1</span>, <span class="va">self</span>.d_model))</span>
<span id="cb8-45"><a href="#cb8-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-46"><a href="#cb8-46" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.dense(concat_attention)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="informer-encoder" class="level1">
<h1>Informer Encoder:</h1>
<p>The <code>InformerEncoder</code> is a custom Keras layer designed to process sequential data using a combination of attention and convolutional mechanisms. Within the encoder, the input data undergoes multi-head self-attention, utilizing the <code>ProbSparseSelfAttention</code> mechanism, to capture relationships in the data regardless of their distance. Post attention, the data is transformed and normalized, then further processed using two 1D convolutional layers, emphasizing local features in the data. After another normalization step, the processed data is pooled to a lower dimensionality, ensuring the model captures global context, and then passed through a dense layer to produce the final output.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> InformerEncoder(tf.keras.layers.Layer):</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, d_model, num_heads, conv_filters, <span class="op">**</span>kwargs):</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(InformerEncoder, <span class="va">self</span>).<span class="fu">__init__</span>(<span class="op">**</span>kwargs)</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.d_model <span class="op">=</span> d_model</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.num_heads <span class="op">=</span> num_heads</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Assert that d_model is divisible by num_heads</span></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>        <span class="cf">assert</span> <span class="va">self</span>.d_model <span class="op">%</span> <span class="va">self</span>.num_heads <span class="op">==</span> <span class="dv">0</span>, <span class="ss">f"d_model (</span><span class="sc">{</span>d_model<span class="sc">}</span><span class="ss">) must be divisible by num_heads (</span><span class="sc">{</span>num_heads<span class="sc">}</span><span class="ss">)"</span></span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.self_attention <span class="op">=</span> ProbSparseSelfAttention(d_model<span class="op">=</span>d_model, num_heads<span class="op">=</span>num_heads)</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.norm1 <span class="op">=</span> tf.keras.layers.LayerNormalization(epsilon<span class="op">=</span><span class="fl">1e-6</span>)</span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>        <span class="co"># This dense layer will transform the input 'x' to have the dimensionality 'd_model'</span></span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dense_transform <span class="op">=</span> tf.keras.layers.Dense(d_model)</span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv1 <span class="op">=</span> tf.keras.layers.Conv1D(conv_filters, <span class="dv">3</span>, padding<span class="op">=</span><span class="st">'same'</span>)</span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv2 <span class="op">=</span> tf.keras.layers.Conv1D(d_model, <span class="dv">3</span>, padding<span class="op">=</span><span class="st">'same'</span>)</span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.norm2 <span class="op">=</span> tf.keras.layers.LayerNormalization(epsilon<span class="op">=</span><span class="fl">1e-6</span>)</span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.global_avg_pooling <span class="op">=</span> tf.keras.layers.GlobalAveragePooling1D()</span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dense <span class="op">=</span> tf.keras.layers.Dense(d_model)</span>
<span id="cb9-23"><a href="#cb9-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-24"><a href="#cb9-24" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> call(<span class="va">self</span>, x):</span>
<span id="cb9-25"><a href="#cb9-25" aria-hidden="true" tabindex="-1"></a>        attn_output <span class="op">=</span> <span class="va">self</span>.self_attention(x, x, x)</span>
<span id="cb9-26"><a href="#cb9-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-27"><a href="#cb9-27" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Transform 'x' to have the desired dimensionality</span></span>
<span id="cb9-28"><a href="#cb9-28" aria-hidden="true" tabindex="-1"></a>        x_transformed <span class="op">=</span> <span class="va">self</span>.dense_transform(x)</span>
<span id="cb9-29"><a href="#cb9-29" aria-hidden="true" tabindex="-1"></a>        attn_output <span class="op">=</span> <span class="va">self</span>.norm1(attn_output <span class="op">+</span> x_transformed)</span>
<span id="cb9-30"><a href="#cb9-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-31"><a href="#cb9-31" aria-hidden="true" tabindex="-1"></a>        conv_output <span class="op">=</span> <span class="va">self</span>.conv1(attn_output)</span>
<span id="cb9-32"><a href="#cb9-32" aria-hidden="true" tabindex="-1"></a>        conv_output <span class="op">=</span> tf.nn.relu(conv_output)</span>
<span id="cb9-33"><a href="#cb9-33" aria-hidden="true" tabindex="-1"></a>        conv_output <span class="op">=</span> <span class="va">self</span>.conv2(conv_output)</span>
<span id="cb9-34"><a href="#cb9-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-35"><a href="#cb9-35" aria-hidden="true" tabindex="-1"></a>        encoded_output <span class="op">=</span> <span class="va">self</span>.norm2(conv_output <span class="op">+</span> attn_output)</span>
<span id="cb9-36"><a href="#cb9-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-37"><a href="#cb9-37" aria-hidden="true" tabindex="-1"></a>        pooled_output <span class="op">=</span> <span class="va">self</span>.global_avg_pooling(encoded_output)</span>
<span id="cb9-38"><a href="#cb9-38" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.dense(pooled_output)[:, <span class="op">-</span><span class="dv">4</span>:]</span>
<span id="cb9-39"><a href="#cb9-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-40"><a href="#cb9-40" aria-hidden="true" tabindex="-1"></a></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>input_layer <span class="op">=</span> tf.keras.layers.Input(shape<span class="op">=</span>(look_back, n_features))</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Encoder</span></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>encoder_output <span class="op">=</span> InformerEncoder(d_model<span class="op">=</span><span class="dv">360</span>, num_heads<span class="op">=</span><span class="dv">8</span>, conv_filters<span class="op">=</span><span class="dv">64</span>)(input_layer)</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Decoder (with attention)</span></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>decoder_lstm <span class="op">=</span> tf.keras.layers</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The <code>InformerModel</code> function is designed to create a deep learning architecture tailored for sequential data prediction. It takes an input sequence and processes it using the <code>InformerEncoder</code>, a custom encoder layer, which captures both local and global patterns in the data. Following the encoding step, a decoder structure unravels the encoded data by first repeating the encoder’s output, then passing it through an LSTM layer to retain sequential dependencies, and finally making predictions using a dense layer. The resulting architecture is then compiled with the Adam optimizer and Mean Squared Error loss, ready for training on time series data.</p>
<div class="cell" data-outputid="06079186-8b3b-4c81-cf89-a773eb79deb3">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.layers <span class="im">import</span> RepeatVector</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.layers <span class="im">import</span> Input</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.layers <span class="im">import</span> LSTM</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.layers <span class="im">import</span> Dense</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.models <span class="im">import</span> Model</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.optimizers <span class="im">import</span> Adam</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> InformerModel(input_shape, d_model<span class="op">=</span><span class="dv">64</span>, num_heads<span class="op">=</span><span class="dv">2</span>, conv_filters<span class="op">=</span><span class="dv">256</span>, learning_rate<span class="op">=</span> <span class="fl">1e-3</span>):</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Input</span></span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>    input_layer <span class="op">=</span> Input(shape<span class="op">=</span>input_shape)</span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Encoder</span></span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a>    encoder_output <span class="op">=</span> InformerEncoder(d_model<span class="op">=</span>d_model, num_heads<span class="op">=</span>num_heads, conv_filters<span class="op">=</span>conv_filters)(input_layer)</span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Decoder</span></span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a>    repeated_output <span class="op">=</span> RepeatVector(<span class="dv">4</span>)(encoder_output)  <span class="co"># Repeating encoder's output</span></span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a>    decoder_lstm <span class="op">=</span> LSTM(<span class="dv">312</span>, return_sequences<span class="op">=</span><span class="va">True</span>)(repeated_output)</span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a>    decoder_output <span class="op">=</span> Dense(<span class="dv">4</span>)(decoder_lstm[:, <span class="op">-</span><span class="dv">1</span>, :])  <span class="co"># Use the last sequence output to predict the next value</span></span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-21"><a href="#cb11-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Model</span></span>
<span id="cb11-22"><a href="#cb11-22" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> Model(inputs<span class="op">=</span>input_layer, outputs<span class="op">=</span>decoder_output)</span>
<span id="cb11-23"><a href="#cb11-23" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Compile the model with the specified learning rate</span></span>
<span id="cb11-24"><a href="#cb11-24" aria-hidden="true" tabindex="-1"></a>    optimizer <span class="op">=</span> Adam(learning_rate<span class="op">=</span>learning_rate)</span>
<span id="cb11-25"><a href="#cb11-25" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">compile</span>(optimizer<span class="op">=</span>optimizer, loss<span class="op">=</span><span class="st">'mean_squared_error'</span>)</span>
<span id="cb11-26"><a href="#cb11-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-27"><a href="#cb11-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-28"><a href="#cb11-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-29"><a href="#cb11-29" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> model</span>
<span id="cb11-30"><a href="#cb11-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-31"><a href="#cb11-31" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> InformerModel(input_shape<span class="op">=</span>(look_back, n_features))</span>
<span id="cb11-32"><a href="#cb11-32" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">compile</span>(optimizer<span class="op">=</span><span class="st">'adam'</span>, loss<span class="op">=</span><span class="st">'mean_squared_error'</span>)</span>
<span id="cb11-33"><a href="#cb11-33" aria-hidden="true" tabindex="-1"></a>model.summary()</span>
<span id="cb11-34"><a href="#cb11-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-35"><a href="#cb11-35" aria-hidden="true" tabindex="-1"></a></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Model: "model_10"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_12 (InputLayer)       [(None, 10, 4)]           0         
                                                                 
 informer_encoder_11 (Infor  (None, 4)                 108480    
 merEncoder)                                                     
                                                                 
 repeat_vector_10 (RepeatVe  (None, 4, 4)              0         
 ctor)                                                           
                                                                 
 lstm_10 (LSTM)              (None, 4, 312)            395616    
                                                                 
 tf.__operators__.getitem_1  (None, 312)               0         
 0 (SlicingOpLambda)                                             
                                                                 
 dense_82 (Dense)            (None, 4)                 1252      
                                                                 
=================================================================
Total params: 505348 (1.93 MB)
Trainable params: 505348 (1.93 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________</code></pre>
</div>
</div>
<p>The <code>model.fit</code> method trains the neural network using the provided training data (<code>X_train</code> and <code>y_train</code>) for a total of 50 epochs with mini-batches of 32 samples. During training, 20% of the training data is set aside for validation to monitor and prevent overfitting.</p>
<div class="cell" data-outputid="7a4e35e4-be9b-468e-946b-e114a895022f">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> model.fit(</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>    X_train, y_train,</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>    epochs<span class="op">=</span><span class="dv">50</span>,</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>    batch_size<span class="op">=</span><span class="dv">64</span>,</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>    validation_split<span class="op">=</span><span class="fl">0.3</span>,</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>    shuffle<span class="op">=</span><span class="va">True</span></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/50
11/11 [==============================] - 7s 85ms/step - loss: 0.0148 - val_loss: 0.0845
Epoch 2/50
11/11 [==============================] - 0s 13ms/step - loss: 0.0050 - val_loss: 0.0753
Epoch 3/50
11/11 [==============================] - 0s 13ms/step - loss: 0.0020 - val_loss: 0.0373
Epoch 4/50
11/11 [==============================] - 0s 13ms/step - loss: 8.5089e-04 - val_loss: 0.0167
Epoch 5/50
11/11 [==============================] - 0s 13ms/step - loss: 3.6341e-04 - val_loss: 0.0052
Epoch 6/50
11/11 [==============================] - 0s 13ms/step - loss: 3.2985e-04 - val_loss: 0.0072
Epoch 7/50
11/11 [==============================] - 0s 13ms/step - loss: 3.6485e-04 - val_loss: 0.0032
Epoch 8/50
11/11 [==============================] - 0s 14ms/step - loss: 2.5527e-04 - val_loss: 0.0014
Epoch 9/50
11/11 [==============================] - 0s 19ms/step - loss: 2.0932e-04 - val_loss: 0.0027
Epoch 10/50
11/11 [==============================] - 0s 15ms/step - loss: 2.2858e-04 - val_loss: 0.0012
Epoch 11/50
11/11 [==============================] - 0s 12ms/step - loss: 2.3448e-04 - val_loss: 0.0026
Epoch 12/50
11/11 [==============================] - 0s 12ms/step - loss: 2.2099e-04 - val_loss: 0.0015
Epoch 13/50
11/11 [==============================] - 0s 13ms/step - loss: 1.9906e-04 - val_loss: 0.0023
Epoch 14/50
11/11 [==============================] - 0s 18ms/step - loss: 1.9555e-04 - val_loss: 0.0010
Epoch 15/50
11/11 [==============================] - 0s 16ms/step - loss: 2.4684e-04 - val_loss: 0.0081
Epoch 16/50
11/11 [==============================] - 0s 13ms/step - loss: 5.4148e-04 - val_loss: 0.0014
Epoch 17/50
11/11 [==============================] - 0s 13ms/step - loss: 1.9434e-04 - val_loss: 0.0015
Epoch 18/50
11/11 [==============================] - 0s 12ms/step - loss: 2.0086e-04 - val_loss: 0.0027
Epoch 19/50
11/11 [==============================] - 0s 13ms/step - loss: 2.2898e-04 - val_loss: 0.0047
Epoch 20/50
11/11 [==============================] - 0s 20ms/step - loss: 3.6830e-04 - val_loss: 0.0015
Epoch 21/50
11/11 [==============================] - 0s 13ms/step - loss: 2.1767e-04 - val_loss: 0.0013
Epoch 22/50
11/11 [==============================] - 0s 12ms/step - loss: 1.5870e-04 - val_loss: 0.0014
Epoch 23/50
11/11 [==============================] - 0s 12ms/step - loss: 1.4760e-04 - val_loss: 0.0016
Epoch 24/50
11/11 [==============================] - 0s 12ms/step - loss: 1.5468e-04 - val_loss: 0.0073
Epoch 25/50
11/11 [==============================] - 0s 12ms/step - loss: 5.8333e-04 - val_loss: 0.0073
Epoch 26/50
11/11 [==============================] - 0s 12ms/step - loss: 3.0529e-04 - val_loss: 0.0041
Epoch 27/50
11/11 [==============================] - 0s 13ms/step - loss: 3.8449e-04 - val_loss: 0.0018
Epoch 28/50
11/11 [==============================] - 0s 13ms/step - loss: 2.2575e-04 - val_loss: 0.0016
Epoch 29/50
11/11 [==============================] - 0s 12ms/step - loss: 1.5802e-04 - val_loss: 0.0012
Epoch 30/50
11/11 [==============================] - 0s 12ms/step - loss: 1.1718e-04 - val_loss: 0.0011
Epoch 31/50
11/11 [==============================] - 0s 13ms/step - loss: 1.2446e-04 - val_loss: 9.5531e-04
Epoch 32/50
11/11 [==============================] - 0s 12ms/step - loss: 1.0792e-04 - val_loss: 9.1374e-04
Epoch 33/50
11/11 [==============================] - 0s 13ms/step - loss: 1.1080e-04 - val_loss: 0.0012
Epoch 34/50
11/11 [==============================] - 0s 13ms/step - loss: 1.1769e-04 - val_loss: 7.9812e-04
Epoch 35/50
11/11 [==============================] - 0s 13ms/step - loss: 8.8748e-05 - val_loss: 6.6667e-04
Epoch 36/50
11/11 [==============================] - 0s 12ms/step - loss: 1.0898e-04 - val_loss: 7.7581e-04
Epoch 37/50
11/11 [==============================] - 0s 12ms/step - loss: 8.3250e-05 - val_loss: 0.0014
Epoch 38/50
11/11 [==============================] - 0s 12ms/step - loss: 1.5730e-04 - val_loss: 0.0015
Epoch 39/50
11/11 [==============================] - 0s 13ms/step - loss: 1.6502e-04 - val_loss: 8.1844e-04
Epoch 40/50
11/11 [==============================] - 0s 13ms/step - loss: 1.0669e-04 - val_loss: 8.3199e-04
Epoch 41/50
11/11 [==============================] - 0s 13ms/step - loss: 1.1308e-04 - val_loss: 0.0012
Epoch 42/50
11/11 [==============================] - 0s 12ms/step - loss: 9.3731e-05 - val_loss: 0.0024
Epoch 43/50
11/11 [==============================] - 0s 12ms/step - loss: 1.5355e-04 - val_loss: 0.0012
Epoch 44/50
11/11 [==============================] - 0s 13ms/step - loss: 1.1790e-04 - val_loss: 0.0011
Epoch 45/50
11/11 [==============================] - 0s 12ms/step - loss: 9.7926e-05 - val_loss: 8.3819e-04
Epoch 46/50
11/11 [==============================] - 0s 12ms/step - loss: 9.0219e-05 - val_loss: 0.0018
Epoch 47/50
11/11 [==============================] - 0s 12ms/step - loss: 1.7545e-04 - val_loss: 0.0079
Epoch 48/50
11/11 [==============================] - 0s 12ms/step - loss: 1.7695e-04 - val_loss: 0.0018
Epoch 49/50
11/11 [==============================] - 0s 12ms/step - loss: 1.4218e-04 - val_loss: 0.0028
Epoch 50/50
11/11 [==============================] - 0s 12ms/step - loss: 2.8367e-04 - val_loss: 0.0022</code></pre>
</div>
</div>
<p>The code displays a visual representation of the model’s training and validation loss over the epochs using a line chart. The x-axis represents the number of epochs, while the y-axis indicates the mean squared error, allowing users to observe how the model’s performance evolves over time.</p>
<div class="cell" data-outputid="6d048896-4367-4409-f893-ca69e5da40e8">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">6</span>))</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">'loss'</span>], label<span class="op">=</span><span class="st">'Training Loss'</span>)</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">'val_loss'</span>], label<span class="op">=</span><span class="st">'Validation Loss'</span>)</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Training and Validation Loss'</span>)</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Epoch'</span>)</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Mean Squared Error'</span>)</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="Multivariate_multistep_Informer_files/figure-html/cell-11-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-outputid="b0d8cb64-a4f3-4590-c3c1-9cd4c9968ca5">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>test_predictions <span class="op">=</span> model.predict(X_test)</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>test_predictions <span class="op">=</span> scaler.inverse_transform(test_predictions)</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>true_values <span class="op">=</span> scaler.inverse_transform(y_test)</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>mse <span class="op">=</span> mean_squared_error(true_values, test_predictions)</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Test MSE: </span><span class="sc">{</span>mse<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>15/15 [==============================] - 1s 3ms/step
Test MSE: 462.6375895467179</code></pre>
</div>
</div>
<div class="cell" data-outputid="663eaf95-851a-439c-bf7e-87620568ecb3">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">6</span>))</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>plt.plot(true_values, label<span class="op">=</span><span class="st">'True Values'</span>)</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>plt.plot(test_predictions, label<span class="op">=</span><span class="st">'Predictions'</span>, alpha<span class="op">=</span><span class="fl">0.6</span>)</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Test Set Predictions vs. True Values'</span>)</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="Multivariate_multistep_Informer_files/figure-html/cell-13-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-outputid="3322fbf2-f42b-443e-a0bc-0ebe3a8ebcbd">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install keras<span class="op">-</span>tuner</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Requirement already satisfied: keras-tuner in /usr/local/lib/python3.10/dist-packages (1.4.4)
Requirement already satisfied: keras-core in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (0.1.7)
Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (23.2)
Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.31.0)
Requirement already satisfied: kt-legacy in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (1.0.5)
Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras-core-&gt;keras-tuner) (1.4.0)
Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras-core-&gt;keras-tuner) (1.23.5)
Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras-core-&gt;keras-tuner) (13.6.0)
Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras-core-&gt;keras-tuner) (0.0.7)
Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras-core-&gt;keras-tuner) (3.9.0)
Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from keras-core-&gt;keras-tuner) (0.1.8)
Requirement already satisfied: charset-normalizer&lt;4,&gt;=2 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;keras-tuner) (3.3.0)
Requirement already satisfied: idna&lt;4,&gt;=2.5 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;keras-tuner) (3.4)
Requirement already satisfied: urllib3&lt;3,&gt;=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;keras-tuner) (2.0.6)
Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;keras-tuner) (2023.7.22)
Requirement already satisfied: markdown-it-py&gt;=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich-&gt;keras-core-&gt;keras-tuner) (3.0.0)
Requirement already satisfied: pygments&lt;3.0.0,&gt;=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich-&gt;keras-core-&gt;keras-tuner) (2.16.1)
Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py&gt;=2.2.0-&gt;rich-&gt;keras-core-&gt;keras-tuner) (0.1.2)</code></pre>
</div>
</div>
<p>The code defines a function to construct a neural network model using varying hyperparameters, aiming to optimize its architecture. Subsequently, the RandomSearch method from Keras Tuner is employed to explore 200 different model configurations, assessing their performance to determine the best hyperparameters that minimize the validation loss.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.layers <span class="im">import</span> Input, RepeatVector, LSTM, Dense</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.models <span class="im">import</span> Model</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.optimizers <span class="im">import</span> Adam</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> kerastuner <span class="im">as</span> kt</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> build_model(hp):</span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Input</span></span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>    input_layer <span class="op">=</span> Input(shape<span class="op">=</span>(look_back, n_features))</span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Encoder</span></span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a>    encoder_output <span class="op">=</span> InformerEncoder(d_model<span class="op">=</span>hp.Int(<span class="st">'d_model'</span>, min_value<span class="op">=</span><span class="dv">32</span>, max_value<span class="op">=</span><span class="dv">512</span>, step<span class="op">=</span><span class="dv">16</span>),</span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a>                                     num_heads<span class="op">=</span>hp.Int(<span class="st">'num_heads'</span>, <span class="dv">2</span>, <span class="dv">8</span>, step<span class="op">=</span><span class="dv">2</span>),</span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a>                                     conv_filters<span class="op">=</span>hp.Int(<span class="st">'conv_filters'</span>, min_value<span class="op">=</span><span class="dv">16</span>, max_value<span class="op">=</span><span class="dv">256</span>, step<span class="op">=</span><span class="dv">16</span>))(input_layer)</span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Decoder</span></span>
<span id="cb21-17"><a href="#cb21-17" aria-hidden="true" tabindex="-1"></a>    repeated_output <span class="op">=</span> RepeatVector(<span class="dv">4</span>)(encoder_output)  <span class="co"># Repeating encoder's output</span></span>
<span id="cb21-18"><a href="#cb21-18" aria-hidden="true" tabindex="-1"></a>    decoder_lstm <span class="op">=</span> LSTM(<span class="dv">312</span>, return_sequences<span class="op">=</span><span class="va">True</span>)(repeated_output)</span>
<span id="cb21-19"><a href="#cb21-19" aria-hidden="true" tabindex="-1"></a>    decoder_output <span class="op">=</span> Dense(<span class="dv">4</span>)(decoder_lstm[:, <span class="op">-</span><span class="dv">1</span>, :])  <span class="co"># Use the last sequence output to predict the next value</span></span>
<span id="cb21-20"><a href="#cb21-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-21"><a href="#cb21-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Model</span></span>
<span id="cb21-22"><a href="#cb21-22" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> Model(inputs<span class="op">=</span>input_layer, outputs<span class="op">=</span>decoder_output)</span>
<span id="cb21-23"><a href="#cb21-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-24"><a href="#cb21-24" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Compile the model with the specified learning rate</span></span>
<span id="cb21-25"><a href="#cb21-25" aria-hidden="true" tabindex="-1"></a>    optimizer <span class="op">=</span> Adam(learning_rate<span class="op">=</span>hp.Choice(<span class="st">'learning_rate'</span>, [<span class="fl">1e-3</span>, <span class="fl">1e-2</span>, <span class="fl">1e-1</span>]))</span>
<span id="cb21-26"><a href="#cb21-26" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">compile</span>(optimizer<span class="op">=</span>optimizer, loss<span class="op">=</span><span class="st">'mean_squared_error'</span>)</span>
<span id="cb21-27"><a href="#cb21-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-28"><a href="#cb21-28" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> model</span>
<span id="cb21-29"><a href="#cb21-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-30"><a href="#cb21-30" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the tuner</span></span>
<span id="cb21-31"><a href="#cb21-31" aria-hidden="true" tabindex="-1"></a>tuner <span class="op">=</span> kt.RandomSearch(</span>
<span id="cb21-32"><a href="#cb21-32" aria-hidden="true" tabindex="-1"></a>    build_model,</span>
<span id="cb21-33"><a href="#cb21-33" aria-hidden="true" tabindex="-1"></a>    objective<span class="op">=</span><span class="st">'val_loss'</span>,</span>
<span id="cb21-34"><a href="#cb21-34" aria-hidden="true" tabindex="-1"></a>    max_trials<span class="op">=</span><span class="dv">30</span>,</span>
<span id="cb21-35"><a href="#cb21-35" aria-hidden="true" tabindex="-1"></a>    executions_per_trial<span class="op">=</span><span class="dv">5</span>,</span>
<span id="cb21-36"><a href="#cb21-36" aria-hidden="true" tabindex="-1"></a>    directory<span class="op">=</span><span class="st">'hyperparam_search'</span>,</span>
<span id="cb21-37"><a href="#cb21-37" aria-hidden="true" tabindex="-1"></a>    project_name<span class="op">=</span><span class="st">'informer_model'</span></span>
<span id="cb21-38"><a href="#cb21-38" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The code sets up two training callbacks: one for early stopping if validation loss doesn’t improve after 10 epochs, and another to save the model weights at their best performance. With these callbacks, the tuner conducts a search over the hyperparameter space using the training data, and evaluates model configurations over 100 epochs, saving the most optimal weights and potentially halting early if improvements stagnate.</p>
<div class="cell" data-outputid="9328634e-67aa-484c-9bd3-8cfa40d580c2">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.callbacks <span class="im">import</span> EarlyStopping, ModelCheckpoint</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>early_stopping <span class="op">=</span> EarlyStopping(monitor<span class="op">=</span><span class="st">'val_loss'</span>, patience<span class="op">=</span><span class="dv">10</span>, verbose<span class="op">=</span><span class="dv">1</span>, restore_best_weights<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>model_checkpoint <span class="op">=</span> ModelCheckpoint(filepath<span class="op">=</span><span class="st">'trial_best.h5'</span>, monitor<span class="op">=</span><span class="st">'val_loss'</span>, verbose<span class="op">=</span><span class="dv">1</span>, save_best_only<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>tuner.search(X_train, y_train,</span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>             epochs<span class="op">=</span><span class="dv">100</span>,</span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>             validation_split<span class="op">=</span><span class="fl">0.2</span>,</span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a>             callbacks<span class="op">=</span>[early_stopping, model_checkpoint])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Trial 30 Complete [00h 00m 01s]

Best val_loss So Far: 0.0009468139498494566
Total elapsed time: 00h 30m 43s</code></pre>
</div>
</div>
<div class="cell" data-outputid="f09fb52a-b6ff-454c-a48a-ea04fb42b7bc">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the best hyperparameters</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>best_hp <span class="op">=</span> tuner.get_best_hyperparameters()[<span class="dv">0</span>]</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Retrieve the best model</span></span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>best_model <span class="op">=</span> tuner.get_best_models()[<span class="dv">0</span>]</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>best_model.summary()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_1 (InputLayer)        [(None, 10, 4)]           0         
                                                                 
 informer_encoder (Informer  (None, 4)                 108480    
 Encoder)                                                        
                                                                 
 repeat_vector (RepeatVecto  (None, 4, 4)              0         
 r)                                                              
                                                                 
 lstm (LSTM)                 (None, 4, 312)            395616    
                                                                 
 tf.__operators__.getitem (  (None, 312)               0         
 SlicingOpLambda)                                                
                                                                 
 dense_6 (Dense)             (None, 4)                 1252      
                                                                 
=================================================================
Total params: 505348 (1.93 MB)
Trainable params: 505348 (1.93 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________</code></pre>
</div>
</div>
<div class="cell" data-outputid="3cc8f6ef-3e93-4320-e75e-522e194c09e4">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>test_loss <span class="op">=</span> best_model.evaluate(X_test, y_test)</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Test MSE: </span><span class="sc">{</span>test_loss<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>15/15 [==============================] - 0s 3ms/step - loss: 0.0086
Test MSE: 0.008609036915004253</code></pre>
</div>
</div>
<div class="cell" data-outputid="759bdc9a-3d06-4f92-d17e-cff1c1f74c44">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">20</span>, <span class="dv">12</span>))</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(true_values.shape[<span class="dv">1</span>]):</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>    plt.subplot(<span class="dv">2</span>, <span class="dv">2</span>, i<span class="op">+</span><span class="dv">1</span>)</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>    plt.plot(true_values[:, i], label<span class="op">=</span><span class="st">'True Values'</span>, color<span class="op">=</span><span class="st">'blue'</span>)</span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>    plt.plot(test_predictions[:, i], label<span class="op">=</span><span class="st">'Predictions'</span>, color<span class="op">=</span><span class="st">'red'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>)</span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="ss">f"Feature </span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>    plt.legend()</span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="Multivariate_multistep_Informer_files/figure-html/cell-19-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-outputid="bf20d53b-541a-48f6-be54-d5af516709c4">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> mean_absolute_error</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>mae <span class="op">=</span> mean_absolute_error(true_values, test_predictions)</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>rmse <span class="op">=</span> np.sqrt(test_loss)  <span class="co"># since loss is MSE</span></span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"MAE: </span><span class="sc">{</span>mae<span class="sc">}</span><span class="ss">, RMSE: </span><span class="sc">{</span>rmse<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>MAE: 19.377517553476185, RMSE: 0.09278489594219662</code></pre>
</div>
</div>
<div class="cell" data-outputid="d2cc4818-993e-461e-c851-dd84607ad237">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Best d_model: </span><span class="sc">{</span>best_hp<span class="sc">.</span>get(<span class="st">'d_model'</span>)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Best num_heads: </span><span class="sc">{</span>best_hp<span class="sc">.</span>get(<span class="st">'num_heads'</span>)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Best conv_filters: </span><span class="sc">{</span>best_hp<span class="sc">.</span>get(<span class="st">'conv_filters'</span>)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Best learning_rate: </span><span class="sc">{</span>best_hp<span class="sc">.</span>get(<span class="st">'learning_rate'</span>)<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Best d_model: 64
Best num_heads: 2
Best conv_filters: 256
Best learning_rate: 0.001</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install shap</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> shap</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="co"># The reference can be a dataset or just random data</span></span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>background <span class="op">=</span> X_train[np.random.choice(X_train.shape[<span class="dv">0</span>], <span class="dv">300</span>, replace<span class="op">=</span><span class="va">False</span>)]  <span class="co"># Taking a random sample of the training data as background</span></span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>explainer <span class="op">=</span> shap.GradientExplainer(best_model, background)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>shap_values <span class="op">=</span> explainer.shap_values(X_test[:<span class="dv">300</span>])  <span class="co"># Computing for a subset for performance reasons</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-outputid="71792e0e-6c53-4d3c-cac9-76f662b0cbf4">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> timestep <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">10</span>):</span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Summary plot for timestep </span><span class="sc">{</span>timestep <span class="op">+</span> <span class="dv">1</span><span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a>    shap.summary_plot(shap_values[<span class="dv">0</span>][:, timestep, :], X_test[:<span class="dv">300</span>, timestep, :])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Summary plot for timestep 1
Summary plot for timestep 2
Summary plot for timestep 3
Summary plot for timestep 4
Summary plot for timestep 5
Summary plot for timestep 6
Summary plot for timestep 7
Summary plot for timestep 8
Summary plot for timestep 9
Summary plot for timestep 10</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="Multivariate_multistep_Informer_files/figure-html/cell-25-output-2.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="Multivariate_multistep_Informer_files/figure-html/cell-25-output-3.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="Multivariate_multistep_Informer_files/figure-html/cell-25-output-4.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="Multivariate_multistep_Informer_files/figure-html/cell-25-output-5.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="Multivariate_multistep_Informer_files/figure-html/cell-25-output-6.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="Multivariate_multistep_Informer_files/figure-html/cell-25-output-7.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="Multivariate_multistep_Informer_files/figure-html/cell-25-output-8.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="Multivariate_multistep_Informer_files/figure-html/cell-25-output-9.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="Multivariate_multistep_Informer_files/figure-html/cell-25-output-10.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="Multivariate_multistep_Informer_files/figure-html/cell-25-output-11.png" class="img-fluid"></p>
</div>
</div>
<p># Shapley values</p>
<p>SHAP values are indicating by how much the presence of a particular feature influenced the model’s prediction, compared to if that feature was absent. The color represents the actual value of the feature itself. In the context of the present work, Shapley values are employed as a method to enhance the interpretability of the model. Shapley values provide insights into the contribution of each feature to the model’s predictions. Specifically, they quantify how each feature influences the prediction by evaluating its impact when combined with all other features. By calculating Shapley values, we gain a clear understanding of the relative importance of each feature in multivariate time series prediction.</p>
<p>Overall, Shapley values enhance model interpretability by offering a systematic and quantitative way to dissect complex models and understand their decision-making processes. They enable us to identify which features are the key drivers of predictions, helping us make more informed decisions and potentially improving model performance. This interpretability is crucial in various applications, from finance to healthcare, where understanding the factors influencing predictions is paramount for trust and decision-making.</p>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>jupyter nbconvert Multivariate_multistep_Informer.ipynb <span class="op">--</span>to markdown <span class="op">--</span>NbConvertApp.output_files_dir<span class="op">=</span>.</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[NbConvertApp] Converting notebook Multivariate_multistep_Informer.ipynb to markdown
[NbConvertApp] Support files will be in ./
[NbConvertApp] Writing 31740 bytes to Multivariate_multistep_Informer.md</code></pre>
</div>
</div>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>cat covid_analysis.md <span class="op">|</span> tee <span class="op">-</span>a index.md</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>cat: covid_analysis.md: No such file or directory</code></pre>
</div>
</div>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>cat Multivariate_multistep_Informer.md <span class="op">|</span> tee <span class="op">-</span>a index.md</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>```python
!pip install yfinance
```

    Requirement already satisfied: yfinance in /home/deepak/anaconda3/lib/python3.7/site-packages (0.1.81)
    Requirement already satisfied: pandas&gt;=0.24.0 in /home/deepak/anaconda3/lib/python3.7/site-packages (from yfinance) (1.3.5)
    Requirement already satisfied: numpy&gt;=1.15 in /home/deepak/anaconda3/lib/python3.7/site-packages (from yfinance) (1.21.5)
    Requirement already satisfied: requests&gt;=2.26 in /home/deepak/anaconda3/lib/python3.7/site-packages (from yfinance) (2.31.0)
    Requirement already satisfied: multitasking&gt;=0.0.7 in /home/deepak/anaconda3/lib/python3.7/site-packages (from yfinance) (0.0.11)
    Requirement already satisfied: lxml&gt;=4.5.1 in /home/deepak/anaconda3/lib/python3.7/site-packages (from yfinance) (4.9.1)
    Requirement already satisfied: appdirs&gt;=1.4.4 in /home/deepak/anaconda3/lib/python3.7/site-packages (from yfinance) (1.4.4)
    Requirement already satisfied: python-dateutil&gt;=2.7.3 in /home/deepak/anaconda3/lib/python3.7/site-packages (from pandas&gt;=0.24.0-&gt;yfinance) (2.8.2)
    Requirement already satisfied: pytz&gt;=2017.3 in /home/deepak/anaconda3/lib/python3.7/site-packages (from pandas&gt;=0.24.0-&gt;yfinance) (2023.3)
    Requirement already satisfied: charset-normalizer&lt;4,&gt;=2 in /home/deepak/anaconda3/lib/python3.7/site-packages (from requests&gt;=2.26-&gt;yfinance) (2.1.1)
    Requirement already satisfied: idna&lt;4,&gt;=2.5 in /home/deepak/anaconda3/lib/python3.7/site-packages (from requests&gt;=2.26-&gt;yfinance) (3.4)
    Requirement already satisfied: urllib3&lt;3,&gt;=1.21.1 in /home/deepak/anaconda3/lib/python3.7/site-packages (from requests&gt;=2.26-&gt;yfinance) (2.0.4)
    Requirement already satisfied: certifi&gt;=2017.4.17 in /home/deepak/anaconda3/lib/python3.7/site-packages (from requests&gt;=2.26-&gt;yfinance) (2023.7.22)
    Requirement already satisfied: six&gt;=1.5 in /home/deepak/anaconda3/lib/python3.7/site-packages (from python-dateutil&gt;=2.7.3-&gt;pandas&gt;=0.24.0-&gt;yfinance) (1.16.0)



```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error
import tensorflow as tf
import yfinance as yf
```


```python
# Download historical data as dataframe
data = yf.download("AAPL", start="2018-01-01", end="2023-09-01")

```

    [*********************100%***********************]  1 of 1 completed
    
    1 Failed download:
    - AAPL: No data found for this date range, symbol may be delisted


# Informer

The Informer model variant is designed for multivariate prediction. Let's consider 'Open', 'High', 'Low', and 'Close' prices for simplicity. The provided code is designed to fetch and preprocess historical stock prices for Apple Inc. for the purpose of multivariate time series forecasting using an LSTM model. Initially, the code downloads Apple's stock data, specifically capturing four significant features: Open, High, Low, and Close prices. To make the data suitable for deep learning models, it is normalized to fit within a range of 0 to 1. The sequential data is then transformed into a format suitable for supervised learning, where the data from the past `look_back` days is used to predict the next day's features. Finally, the data is partitioned into training (67%) and test sets, ensuring separate datasets for model training and evaluation.



```python
# Using multiple columns for multivariate prediction
df = data[["Open", "High", "Low", "Close"]]

# Normalize the data
scaler = MinMaxScaler(feature_range=(0, 1))
df_scaled = scaler.fit_transform(df)

# Prepare data for LSTM
look_back = 10  # Number of previous time steps to use as input variables
n_features = df.shape[1]  # number of features

# Convert to supervised learning problem
X, y = [], []
for i in range(len(df_scaled) - look_back):
    X.append(df_scaled[i:i+look_back, :])
    y.append(df_scaled[i + look_back, :])
X, y = np.array(X), np.array(y)

# Reshape input to be [samples, time steps, features]
X = np.reshape(X, (X.shape[0], X.shape[1], n_features))

# Train-test split
train_size = int(len(X) * 0.67)
test_size = len(X) - train_size
X_train, X_test = X[0:train_size], X[train_size:]
y_train, y_test = y[0:train_size], y[train_size:]

print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)
```


    ---------------------------------------------------------------------------

    NameError                                 Traceback (most recent call last)

    /tmp/ipykernel_584257/995404858.py in &lt;module&gt;
          1 # Using multiple columns for multivariate prediction
    ----&gt; 2 df = data[["Open", "High", "Low", "Close"]]
          3 
          4 # Normalize the data
          5 scaler = MinMaxScaler(feature_range=(0, 1))


    NameError: name 'data' is not defined


# ProbSparse Self-Attention:

Self-attention involves computing a weighted sum of all values in the sequence, based on the dot product between the query and key. In ProbSparse, we don't compute this for all query-key pairs, but rather select dominant ones, thus making the computation more efficient. The given code defines a custom Keras layer, `ProbSparseSelfAttention`, which implements the multi-head self-attention mechanism, a critical component of Transformer models. This layer initializes three dense networks for the Query, Key, and Value matrices, and splits the input data into multiple heads to enable parallel processing. During the forward pass (`call` method), the Query, Key, and Value matrices are calculated, scaled, and then used to compute attention scores. These scores indicate the importance of each element in the sequence when predicting another element. The output is a weighted sum of the input values, which is then passed through another dense layer to produce the final result.



```python
class ProbSparseSelfAttention(tf.keras.layers.Layer):
    def __init__(self, d_model, num_heads, **kwargs):
        super(ProbSparseSelfAttention, self).__init__(**kwargs)
        self.num_heads = num_heads
        self.d_model = d_model

        # Assert that d_model is divisible by num_heads
        assert self.d_model % self.num_heads == 0, f"d_model ({d_model}) must be divisible by num_heads ({num_heads})"

        self.depth = d_model // self.num_heads

        # Defining the dense layers for Query, Key and Value
        self.wq = tf.keras.layers.Dense(d_model)
        self.wk = tf.keras.layers.Dense(d_model)
        self.wv = tf.keras.layers.Dense(d_model)

        self.dense = tf.keras.layers.Dense(d_model)

    def split_heads(self, x, batch_size):
        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))
        return tf.transpose(x, perm=[0, 2, 1, 3])

    def call(self, v, k, q):
        batch_size = tf.shape(q)[0]

        q = self.wq(q)
        k = self.wk(k)
        v = self.wv(v)

        q = self.split_heads(q, batch_size)
        k = self.split_heads(k, batch_size)
        v = self.split_heads(v, batch_size)

        # Fixing matrix multiplication
        matmul_qk = tf.matmul(q, k, transpose_b=True)

        d_k = tf.cast(self.depth, tf.float32)
        scaled_attention_logits = matmul_qk / tf.math.sqrt(d_k)

        attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)
        output = tf.matmul(attention_weights, v)

        output = tf.transpose(output, perm=[0, 2, 1, 3])
        concat_attention = tf.reshape(output, (batch_size, -1, self.d_model))

        return self.dense(concat_attention)

```

# Informer Encoder:

The `InformerEncoder` is a custom Keras layer designed to process sequential data using a combination of attention and convolutional mechanisms. Within the encoder, the input data undergoes multi-head self-attention, utilizing the `ProbSparseSelfAttention` mechanism, to capture relationships in the data regardless of their distance. Post attention, the data is transformed and normalized, then further processed using two 1D convolutional layers, emphasizing local features in the data. After another normalization step, the processed data is pooled to a lower dimensionality, ensuring the model captures global context, and then passed through a dense layer to produce the final output.



```python
class InformerEncoder(tf.keras.layers.Layer):
    def __init__(self, d_model, num_heads, conv_filters, **kwargs):
        super(InformerEncoder, self).__init__(**kwargs)
        self.d_model = d_model
        self.num_heads = num_heads

        # Assert that d_model is divisible by num_heads
        assert self.d_model % self.num_heads == 0, f"d_model ({d_model}) must be divisible by num_heads ({num_heads})"

        self.self_attention = ProbSparseSelfAttention(d_model=d_model, num_heads=num_heads)

        self.norm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)

        # This dense layer will transform the input 'x' to have the dimensionality 'd_model'
        self.dense_transform = tf.keras.layers.Dense(d_model)

        self.conv1 = tf.keras.layers.Conv1D(conv_filters, 3, padding='same')
        self.conv2 = tf.keras.layers.Conv1D(d_model, 3, padding='same')
        self.norm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)

        self.global_avg_pooling = tf.keras.layers.GlobalAveragePooling1D()
        self.dense = tf.keras.layers.Dense(d_model)

    def call(self, x):
        attn_output = self.self_attention(x, x, x)

        # Transform 'x' to have the desired dimensionality
        x_transformed = self.dense_transform(x)
        attn_output = self.norm1(attn_output + x_transformed)

        conv_output = self.conv1(attn_output)
        conv_output = tf.nn.relu(conv_output)
        conv_output = self.conv2(conv_output)

        encoded_output = self.norm2(conv_output + attn_output)

        pooled_output = self.global_avg_pooling(encoded_output)
        return self.dense(pooled_output)[:, -4:]



```


```python
input_layer = tf.keras.layers.Input(shape=(look_back, n_features))

# Encoder
encoder_output = InformerEncoder(d_model=360, num_heads=8, conv_filters=64)(input_layer)

# Decoder (with attention)
decoder_lstm = tf.keras.layers
```

The `InformerModel` function is designed to create a deep learning architecture tailored for sequential data prediction. It takes an input sequence and processes it using the `InformerEncoder`, a custom encoder layer, which captures both local and global patterns in the data. Following the encoding step, a decoder structure unravels the encoded data by first repeating the encoder's output, then passing it through an LSTM layer to retain sequential dependencies, and finally making predictions using a dense layer. The resulting architecture is then compiled with the Adam optimizer and Mean Squared Error loss, ready for training on time series data.



```python
from tensorflow.keras.layers import RepeatVector
from tensorflow.keras.layers import Input
from tensorflow.keras.layers import LSTM
from tensorflow.keras.layers import Dense
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam


def InformerModel(input_shape, d_model=64, num_heads=2, conv_filters=256, learning_rate= 1e-3):
    # Input
    input_layer = Input(shape=input_shape)

    # Encoder
    encoder_output = InformerEncoder(d_model=d_model, num_heads=num_heads, conv_filters=conv_filters)(input_layer)

    # Decoder
    repeated_output = RepeatVector(4)(encoder_output)  # Repeating encoder's output
    decoder_lstm = LSTM(312, return_sequences=True)(repeated_output)
    decoder_output = Dense(4)(decoder_lstm[:, -1, :])  # Use the last sequence output to predict the next value

    # Model
    model = Model(inputs=input_layer, outputs=decoder_output)
    # Compile the model with the specified learning rate
    optimizer = Adam(learning_rate=learning_rate)
    model.compile(optimizer=optimizer, loss='mean_squared_error')



    return model

model = InformerModel(input_shape=(look_back, n_features))
model.compile(optimizer='adam', loss='mean_squared_error')
model.summary()



```

    Model: "model_10"
    _________________________________________________________________
     Layer (type)                Output Shape              Param #   
    =================================================================
     input_12 (InputLayer)       [(None, 10, 4)]           0         
                                                                     
     informer_encoder_11 (Infor  (None, 4)                 108480    
     merEncoder)                                                     
                                                                     
     repeat_vector_10 (RepeatVe  (None, 4, 4)              0         
     ctor)                                                           
                                                                     
     lstm_10 (LSTM)              (None, 4, 312)            395616    
                                                                     
     tf.__operators__.getitem_1  (None, 312)               0         
     0 (SlicingOpLambda)                                             
                                                                     
     dense_82 (Dense)            (None, 4)                 1252      
                                                                     
    =================================================================
    Total params: 505348 (1.93 MB)
    Trainable params: 505348 (1.93 MB)
    Non-trainable params: 0 (0.00 Byte)
    _________________________________________________________________


The `model.fit` method trains the neural network using the provided training data (`X_train` and `y_train`) for a total of 50 epochs with mini-batches of 32 samples. During training, 20% of the training data is set aside for validation to monitor and prevent overfitting.



```python
history = model.fit(
    X_train, y_train,
    epochs=50,
    batch_size=64,
    validation_split=0.3,
    shuffle=True
)

```

    Epoch 1/50
    11/11 [==============================] - 7s 85ms/step - loss: 0.0148 - val_loss: 0.0845
    Epoch 2/50
    11/11 [==============================] - 0s 13ms/step - loss: 0.0050 - val_loss: 0.0753
    Epoch 3/50
    11/11 [==============================] - 0s 13ms/step - loss: 0.0020 - val_loss: 0.0373
    Epoch 4/50
    11/11 [==============================] - 0s 13ms/step - loss: 8.5089e-04 - val_loss: 0.0167
    Epoch 5/50
    11/11 [==============================] - 0s 13ms/step - loss: 3.6341e-04 - val_loss: 0.0052
    Epoch 6/50
    11/11 [==============================] - 0s 13ms/step - loss: 3.2985e-04 - val_loss: 0.0072
    Epoch 7/50
    11/11 [==============================] - 0s 13ms/step - loss: 3.6485e-04 - val_loss: 0.0032
    Epoch 8/50
    11/11 [==============================] - 0s 14ms/step - loss: 2.5527e-04 - val_loss: 0.0014
    Epoch 9/50
    11/11 [==============================] - 0s 19ms/step - loss: 2.0932e-04 - val_loss: 0.0027
    Epoch 10/50
    11/11 [==============================] - 0s 15ms/step - loss: 2.2858e-04 - val_loss: 0.0012
    Epoch 11/50
    11/11 [==============================] - 0s 12ms/step - loss: 2.3448e-04 - val_loss: 0.0026
    Epoch 12/50
    11/11 [==============================] - 0s 12ms/step - loss: 2.2099e-04 - val_loss: 0.0015
    Epoch 13/50
    11/11 [==============================] - 0s 13ms/step - loss: 1.9906e-04 - val_loss: 0.0023
    Epoch 14/50
    11/11 [==============================] - 0s 18ms/step - loss: 1.9555e-04 - val_loss: 0.0010
    Epoch 15/50
    11/11 [==============================] - 0s 16ms/step - loss: 2.4684e-04 - val_loss: 0.0081
    Epoch 16/50
    11/11 [==============================] - 0s 13ms/step - loss: 5.4148e-04 - val_loss: 0.0014
    Epoch 17/50
    11/11 [==============================] - 0s 13ms/step - loss: 1.9434e-04 - val_loss: 0.0015
    Epoch 18/50
    11/11 [==============================] - 0s 12ms/step - loss: 2.0086e-04 - val_loss: 0.0027
    Epoch 19/50
    11/11 [==============================] - 0s 13ms/step - loss: 2.2898e-04 - val_loss: 0.0047
    Epoch 20/50
    11/11 [==============================] - 0s 20ms/step - loss: 3.6830e-04 - val_loss: 0.0015
    Epoch 21/50
    11/11 [==============================] - 0s 13ms/step - loss: 2.1767e-04 - val_loss: 0.0013
    Epoch 22/50
    11/11 [==============================] - 0s 12ms/step - loss: 1.5870e-04 - val_loss: 0.0014
    Epoch 23/50
    11/11 [==============================] - 0s 12ms/step - loss: 1.4760e-04 - val_loss: 0.0016
    Epoch 24/50
    11/11 [==============================] - 0s 12ms/step - loss: 1.5468e-04 - val_loss: 0.0073
    Epoch 25/50
    11/11 [==============================] - 0s 12ms/step - loss: 5.8333e-04 - val_loss: 0.0073
    Epoch 26/50
    11/11 [==============================] - 0s 12ms/step - loss: 3.0529e-04 - val_loss: 0.0041
    Epoch 27/50
    11/11 [==============================] - 0s 13ms/step - loss: 3.8449e-04 - val_loss: 0.0018
    Epoch 28/50
    11/11 [==============================] - 0s 13ms/step - loss: 2.2575e-04 - val_loss: 0.0016
    Epoch 29/50
    11/11 [==============================] - 0s 12ms/step - loss: 1.5802e-04 - val_loss: 0.0012
    Epoch 30/50
    11/11 [==============================] - 0s 12ms/step - loss: 1.1718e-04 - val_loss: 0.0011
    Epoch 31/50
    11/11 [==============================] - 0s 13ms/step - loss: 1.2446e-04 - val_loss: 9.5531e-04
    Epoch 32/50
    11/11 [==============================] - 0s 12ms/step - loss: 1.0792e-04 - val_loss: 9.1374e-04
    Epoch 33/50
    11/11 [==============================] - 0s 13ms/step - loss: 1.1080e-04 - val_loss: 0.0012
    Epoch 34/50
    11/11 [==============================] - 0s 13ms/step - loss: 1.1769e-04 - val_loss: 7.9812e-04
    Epoch 35/50
    11/11 [==============================] - 0s 13ms/step - loss: 8.8748e-05 - val_loss: 6.6667e-04
    Epoch 36/50
    11/11 [==============================] - 0s 12ms/step - loss: 1.0898e-04 - val_loss: 7.7581e-04
    Epoch 37/50
    11/11 [==============================] - 0s 12ms/step - loss: 8.3250e-05 - val_loss: 0.0014
    Epoch 38/50
    11/11 [==============================] - 0s 12ms/step - loss: 1.5730e-04 - val_loss: 0.0015
    Epoch 39/50
    11/11 [==============================] - 0s 13ms/step - loss: 1.6502e-04 - val_loss: 8.1844e-04
    Epoch 40/50
    11/11 [==============================] - 0s 13ms/step - loss: 1.0669e-04 - val_loss: 8.3199e-04
    Epoch 41/50
    11/11 [==============================] - 0s 13ms/step - loss: 1.1308e-04 - val_loss: 0.0012
    Epoch 42/50
    11/11 [==============================] - 0s 12ms/step - loss: 9.3731e-05 - val_loss: 0.0024
    Epoch 43/50
    11/11 [==============================] - 0s 12ms/step - loss: 1.5355e-04 - val_loss: 0.0012
    Epoch 44/50
    11/11 [==============================] - 0s 13ms/step - loss: 1.1790e-04 - val_loss: 0.0011
    Epoch 45/50
    11/11 [==============================] - 0s 12ms/step - loss: 9.7926e-05 - val_loss: 8.3819e-04
    Epoch 46/50
    11/11 [==============================] - 0s 12ms/step - loss: 9.0219e-05 - val_loss: 0.0018
    Epoch 47/50
    11/11 [==============================] - 0s 12ms/step - loss: 1.7545e-04 - val_loss: 0.0079
    Epoch 48/50
    11/11 [==============================] - 0s 12ms/step - loss: 1.7695e-04 - val_loss: 0.0018
    Epoch 49/50
    11/11 [==============================] - 0s 12ms/step - loss: 1.4218e-04 - val_loss: 0.0028
    Epoch 50/50
    11/11 [==============================] - 0s 12ms/step - loss: 2.8367e-04 - val_loss: 0.0022


The code displays a visual representation of the model's training and validation loss over the epochs using a line chart. The x-axis represents the number of epochs, while the y-axis indicates the mean squared error, allowing users to observe how the model's performance evolves over time.



```python
plt.figure(figsize=(12, 6))
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Training and Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Mean Squared Error')
plt.legend()
plt.show()

```


    
![png](./Multivariate_multistep_Informer_15_0.png)
    



```python
test_predictions = model.predict(X_test)
test_predictions = scaler.inverse_transform(test_predictions)
true_values = scaler.inverse_transform(y_test)

mse = mean_squared_error(true_values, test_predictions)
print(f"Test MSE: {mse}")

```

    15/15 [==============================] - 1s 3ms/step
    Test MSE: 462.6375895467179



```python
plt.figure(figsize=(12, 6))
plt.plot(true_values, label='True Values')
plt.plot(test_predictions, label='Predictions', alpha=0.6)
plt.title('Test Set Predictions vs. True Values')
plt.legend()
plt.show()

```


    
![png](./Multivariate_multistep_Informer_17_0.png)
    



```python
!pip install keras-tuner

```

    Requirement already satisfied: keras-tuner in /usr/local/lib/python3.10/dist-packages (1.4.4)
    Requirement already satisfied: keras-core in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (0.1.7)
    Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (23.2)
    Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.31.0)
    Requirement already satisfied: kt-legacy in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (1.0.5)
    Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras-core-&gt;keras-tuner) (1.4.0)
    Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras-core-&gt;keras-tuner) (1.23.5)
    Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras-core-&gt;keras-tuner) (13.6.0)
    Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras-core-&gt;keras-tuner) (0.0.7)
    Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras-core-&gt;keras-tuner) (3.9.0)
    Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from keras-core-&gt;keras-tuner) (0.1.8)
    Requirement already satisfied: charset-normalizer&lt;4,&gt;=2 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;keras-tuner) (3.3.0)
    Requirement already satisfied: idna&lt;4,&gt;=2.5 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;keras-tuner) (3.4)
    Requirement already satisfied: urllib3&lt;3,&gt;=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;keras-tuner) (2.0.6)
    Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;keras-tuner) (2023.7.22)
    Requirement already satisfied: markdown-it-py&gt;=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich-&gt;keras-core-&gt;keras-tuner) (3.0.0)
    Requirement already satisfied: pygments&lt;3.0.0,&gt;=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich-&gt;keras-core-&gt;keras-tuner) (2.16.1)
    Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py&gt;=2.2.0-&gt;rich-&gt;keras-core-&gt;keras-tuner) (0.1.2)


The code defines a function to construct a neural network model using varying hyperparameters, aiming to optimize its architecture. Subsequently, the RandomSearch method from Keras Tuner is employed to explore 200 different model configurations, assessing their performance to determine the best hyperparameters that minimize the validation loss.



```python
from tensorflow.keras.layers import Input, RepeatVector, LSTM, Dense
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
import tensorflow as tf
import kerastuner as kt

def build_model(hp):
    # Input
    input_layer = Input(shape=(look_back, n_features))

    # Encoder
    encoder_output = InformerEncoder(d_model=hp.Int('d_model', min_value=32, max_value=512, step=16),
                                     num_heads=hp.Int('num_heads', 2, 8, step=2),
                                     conv_filters=hp.Int('conv_filters', min_value=16, max_value=256, step=16))(input_layer)

    # Decoder
    repeated_output = RepeatVector(4)(encoder_output)  # Repeating encoder's output
    decoder_lstm = LSTM(312, return_sequences=True)(repeated_output)
    decoder_output = Dense(4)(decoder_lstm[:, -1, :])  # Use the last sequence output to predict the next value

    # Model
    model = Model(inputs=input_layer, outputs=decoder_output)

    # Compile the model with the specified learning rate
    optimizer = Adam(learning_rate=hp.Choice('learning_rate', [1e-3, 1e-2, 1e-1]))
    model.compile(optimizer=optimizer, loss='mean_squared_error')

    return model

# Define the tuner
tuner = kt.RandomSearch(
    build_model,
    objective='val_loss',
    max_trials=30,
    executions_per_trial=5,
    directory='hyperparam_search',
    project_name='informer_model'
)
```

The code sets up two training callbacks: one for early stopping if validation loss doesn't improve after 10 epochs, and another to save the model weights at their best performance. With these callbacks, the tuner conducts a search over the hyperparameter space using the training data, and evaluates model configurations over 100 epochs, saving the most optimal weights and potentially halting early if improvements stagnate.



```python
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint

early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, restore_best_weights=True)
model_checkpoint = ModelCheckpoint(filepath='trial_best.h5', monitor='val_loss', verbose=1, save_best_only=True)

tuner.search(X_train, y_train,
             epochs=100,
             validation_split=0.2,
             callbacks=[early_stopping, model_checkpoint])

```

    Trial 30 Complete [00h 00m 01s]
    
    Best val_loss So Far: 0.0009468139498494566
    Total elapsed time: 00h 30m 43s



```python
# Get the best hyperparameters
best_hp = tuner.get_best_hyperparameters()[0]

# Retrieve the best model
best_model = tuner.get_best_models()[0]
best_model.summary()

```

    Model: "model"
    _________________________________________________________________
     Layer (type)                Output Shape              Param #   
    =================================================================
     input_1 (InputLayer)        [(None, 10, 4)]           0         
                                                                     
     informer_encoder (Informer  (None, 4)                 108480    
     Encoder)                                                        
                                                                     
     repeat_vector (RepeatVecto  (None, 4, 4)              0         
     r)                                                              
                                                                     
     lstm (LSTM)                 (None, 4, 312)            395616    
                                                                     
     tf.__operators__.getitem (  (None, 312)               0         
     SlicingOpLambda)                                                
                                                                     
     dense_6 (Dense)             (None, 4)                 1252      
                                                                     
    =================================================================
    Total params: 505348 (1.93 MB)
    Trainable params: 505348 (1.93 MB)
    Non-trainable params: 0 (0.00 Byte)
    _________________________________________________________________



```python
test_loss = best_model.evaluate(X_test, y_test)
print(f"Test MSE: {test_loss}")

```

    15/15 [==============================] - 0s 3ms/step - loss: 0.0086
    Test MSE: 0.008609036915004253



```python
plt.figure(figsize=(20, 12))
for i in range(true_values.shape[1]):
    plt.subplot(2, 2, i+1)
    plt.plot(true_values[:, i], label='True Values', color='blue')
    plt.plot(test_predictions[:, i], label='Predictions', color='red', linestyle='--')
    plt.title(f"Feature {i+1}")
    plt.legend()
plt.tight_layout()
plt.show()

```


    
![png](./Multivariate_multistep_Informer_25_0.png)
    



```python
from sklearn.metrics import mean_absolute_error
mae = mean_absolute_error(true_values, test_predictions)
rmse = np.sqrt(test_loss)  # since loss is MSE
print(f"MAE: {mae}, RMSE: {rmse}")

```

    MAE: 19.377517553476185, RMSE: 0.09278489594219662



```python
print(f"Best d_model: {best_hp.get('d_model')}")
print(f"Best num_heads: {best_hp.get('num_heads')}")
print(f"Best conv_filters: {best_hp.get('conv_filters')}")
print(f"Best learning_rate: {best_hp.get('learning_rate')}")

```

    Best d_model: 64
    Best num_heads: 2
    Best conv_filters: 256
    Best learning_rate: 0.001



```python
!pip install shap
import shap

```


```python
# The reference can be a dataset or just random data
background = X_train[np.random.choice(X_train.shape[0], 300, replace=False)]  # Taking a random sample of the training data as background
explainer = shap.GradientExplainer(best_model, background)

```


```python
shap_values = explainer.shap_values(X_test[:300])  # Computing for a subset for performance reasons

```


```python
for timestep in range(10):
    print(f"Summary plot for timestep {timestep + 1}")
    shap.summary_plot(shap_values[0][:, timestep, :], X_test[:300, timestep, :])

```

    Summary plot for timestep 1



    
![png](./Multivariate_multistep_Informer_31_1.png)
    


    Summary plot for timestep 2



    
![png](./Multivariate_multistep_Informer_31_3.png)
    


    Summary plot for timestep 3



    
![png](./Multivariate_multistep_Informer_31_5.png)
    


    Summary plot for timestep 4



    
![png](./Multivariate_multistep_Informer_31_7.png)
    


    Summary plot for timestep 5



    
![png](./Multivariate_multistep_Informer_31_9.png)
    


    Summary plot for timestep 6



    
![png](./Multivariate_multistep_Informer_31_11.png)
    


    Summary plot for timestep 7



    
![png](./Multivariate_multistep_Informer_31_13.png)
    


    Summary plot for timestep 8



    
![png](./Multivariate_multistep_Informer_31_15.png)
    


    Summary plot for timestep 9



    
![png](./Multivariate_multistep_Informer_31_17.png)
    


    Summary plot for timestep 10



    
![png](./Multivariate_multistep_Informer_31_19.png)
    


 # Shapley values

 SHAP values are indicating by how much the presence of a particular feature influenced the model's prediction, compared to if that feature was absent. The color represents the actual value of the feature itself. In the context of the present work, Shapley values are employed as a method to enhance the interpretability of the model. Shapley values provide insights into the contribution of each feature to the model's predictions. Specifically, they quantify how each feature influences the prediction by evaluating its impact when combined with all other features. By calculating Shapley values, we gain a clear understanding of the relative importance of each feature in multivariate time series prediction.

Overall, Shapley values enhance model interpretability by offering a systematic and quantitative way to dissect complex models and understand their decision-making processes. They enable us to identify which features are the key drivers of predictions, helping us make more informed decisions and potentially improving model performance. This interpretability is crucial in various applications, from finance to healthcare, where understanding the factors influencing predictions is paramount for trust and decision-making.


```python

```</code></pre>
</div>
</div>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>rm Multivariate_multistep_Informer.md</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  let localAlternateSentinel = 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left"><span class="faux-block">© 2023 Deepak Bastola</span></div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right"><span class="faux-block"><a href="https://github.com/deepbas/">View source on GitHub</a></span></div>
  </div>
</footer>



</body></html>